#!/usr/bin/env python

"""mpistat_process - process the raw data generated by mpistat and produce a basic report"""

from __future__ import print_function

import unicodedata, re
import sys
import time
import grp
import pwd
import base64
import gzip
import csv
import argparse
import json
from collections import namedtuple
from operator import itemgetter

# columns in input file
filestats_field_names = ['volume', 'b64path', 'size', 'uid', 'gid', 'atime', 'mtime', 'ctime', 'type', 'inode', 'nlink', 'dev']

# default parameters
cost_per_TiB_year = 150

# handle command-line arguments
parser = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter)
# required arguments
parser.add_argument("mpistat_input", help="gzip-compressed results from mpistat_tidy")
# optional arguments
parser.add_argument("--cost_per_TiB_year", help="cost per TiB-year of storage", default=cost_per_TiB_year)
parser.add_argument("--output", help="file to output JSON (default: stdout)", default=None) 
args = parser.parse_args()

def warning(*objs):
	"""Print a warning message to standard error"""
	print("WARNING: ", *objs, file=sys.stderr)

FileStatsRow = namedtuple('FileStatsRow', filestats_field_names)

class FileStatsIterable:
	def __init__(self, filename):
		csv.register_dialect('tsv', delimiter="\t", quoting=csv.QUOTE_NONE)
		self.gzfile = gzip.open(filename, "r")
		self.reader = csv.reader(self.gzfile, dialect='tsv')
	def next(self):
		row = self.reader.next()
		return FileStatsRow._make(row)
	def close(self):
		return self.gzfile.close()
	def __iter__(self):
		return self

# prepare uid -> username mapping
uid2username = dict()
for pw in pwd.getpwall():
	uid2username[pw.pw_uid] = pw.pw_name

def getUser(uid):
	return uid2username[uid]

# prepare gid -> group mapping
gid2group = dict()
for gr in grp.getgrall():
	gid2group[gr.gr_gid] = gr.gr_name

def getGroup(gid):
	return gid2group[gid]

# prepare to calculate cost
now=time.time()
def getAgeDays(epoch):
	days=1.0*(now-epoch)/(24.0*60.0*60.0)
	if days < 0:
		days=0.0
	return days

def getGiB(sz):
	return sz/(1024.0*1024.0*1024.0)

def calculateCost(size, epoch):
	size_GiB = getGiB(size)
	age_days = getAgeDays(epoch)
	cost_per_GiB_day = cost_per_TiB_year/365.0/1024.0
	cost = size_GiB * age_days * cost_per_GiB_day
	return cost

# prepare to test for unprintable characters
control_chars = ''.join(map(unichr, range(0,32) + range(127,160)))
control_chars_re = re.compile('[%s]' % re.escape(control_chars))

# set of filenames with unprintable characters
unprintable_files=[]

# if the filename contains non printable character,
# it will add it to the unprintable files list
# and will replace the unprintable characters with '?'
def ensurePrintableFilename(fname):
	if control_chars_re.search(fname):
		fname = control_chars_re.sub('?', fname)
		unprintable_files.append(fname)
	return fname


# TODO: refactor these into container object
by_group=dict()
by_user=dict()
by_user_group=dict()
file_types=dict()
zero_length_files=dict()
costs=[]


def parse_file(mpistat_file):
	mpistat_iter = FileStatsIterable(mpistat_file)

        ###################################
	# the big loop over all the files #
        ###################################
	for filestat in mpistat_iter:
		filename = base64.b64decode(filestat.b64path)

		# check for filenames with dodgy characters
		filename = ensurePrintableFilename(filename)
		
		# cast numeric fields 
		uid=int(filestat.uid)
		gid=int(filestat.gid)
		size=float(filestat.size)
		atime=float(filestat.atime)
		mtime=float(filestat.mtime)
		ctime=float(filestat.ctime)
	
		# lookup username and group
		username=getUser(uid)
		group=getGroup(gid)

		# calculate cost since creation, last modification, and last access
		cost_since_creation = calculateCost(size, ctime)
		cost_since_modification = calculateCost(size, mtime)
		cost_since_access = calculateCost(size, atime)
	
		# fixme hack to only pay attention to ctime cost
		cost = cost_since_creation
		if cost > 0:
			costs.append(cost)

		# counts by type
		if filestat.type in file_types:
			file_types[filestat.type]+=1
		else:
			file_types[filestat.type]=1
		if size == 0:
			if filestat.type in zero_length_files:
				zero_length_files[filestat.type] += 1
			else:
				zero_length_files[filestat.type] = 1

		# by user stuff
		if uid in by_user:
			tmp=by_user[uid]
			tmp['total_cost']+=cost
			tmp['costs'].append(cost)
		else :
			tmp=dict()
			tmp['total_cost'] = cost
			tmp['costs']=[cost]
			by_user[uid]=tmp

		# by_group stuff
		if gid in by_group :
			tmp=by_group[gid]
			tmp['total_cost'] += cost
			tmp['costs'].append(cost)
		else :
			tmp=dict()
			tmp['total_cost'] = cost
			tmp['costs']=[cost]
			by_group[gid]=tmp

		# by_user_group stuff
		user_group=str(uid)+'_'+str(gid)
		if user_group in by_user_group :
			tmp=by_user_group[user_group]
			tmp['total_cost'] += cost
			tmp['costs'].append(cost)
		else :
			tmp=dict()
			tmp['total_cost'] = cost
			tmp['costs']=[cost]
			by_user_group[user_group]=tmp

def report():
	# get the list of total cost per group
	# and sort it then print it
	by_group_list=[]
	for gid in by_group :
		tmp=dict()
		tmp['grp']  = getGroup(gid)
		tmp['cost'] = by_group[gid]['total_cost']
		tmp['gid']  = gid
		by_group_list.append(tmp)
	by_group_list = sorted(by_group_list, key=itemgetter('cost')) 
	by_group_list.reverse()
	print()
	print("top 20 costly groups")
	for d in by_group_list[:20] :
		print('%20s\t%10.2f' % (d['grp'],d['cost']))

	# get the list of total cost per user
	# and sort it then print it
	by_user_list=[]
	for u in by_user :
		tmp=dict()
		tmp['user']  = getUser(u)
		tmp['cost'] = by_user[u]['total_cost']
		tmp['uid']  = u
		by_user_list.append(tmp)
	by_user_list = sorted(by_user_list, key=itemgetter('cost')) 
	by_user_list.reverse()
	print()
	print("top 20 costly users")
	for d in by_user_list[:20] :
		print('%20s\t%10.2f' % (d['user'],d['cost']))

	# get the list of total cost per user / group
	# and sort it then print it
	by_user_group_list=[]
	for ug in by_user_group :
		i=ug.find('_')
		u=int(ug[:i])
		g=int(ug[i+1:])
		tmp=dict()
		tmp['user']  = getUser(u)
		tmp['group'] = getGroup(g)
		tmp['cost'] = by_user_group[ug]['total_cost']
		tmp['uid']  = u
		tmp['gid']  = g
		by_user_group_list.append(tmp)
	by_user_group_list = sorted(by_user_group_list, key=itemgetter('cost')) 
	by_user_group_list.reverse()
	print()
	print("top 40 costly users breakdown by group")
	for d in by_user_group_list[:40] :
		print('%20s\t%s\t%10.2f' % (d['user'],d['group'],d['cost']))

	# print number of occurences of each file type
	print()
	print("number of inodes of each type")
	print(file_types)

	# zero length files
	print()
	print("Number of zero length inodes by type")
	print(str(zero_length_files))

	# unprintable files
	print()
	print("There are "+str(len(unprintable_files))+" unprintable files : ")
	for f in unprintable_files :
		print(f)

def main(args):
	parsed_data = parse_file(args.mpistat_input)
	report(parsed_data)



if __name__=="__main__":
	main(args)
